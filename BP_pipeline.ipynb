{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Monad pipeline\n",
    "For BP purposes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3247adf23f94e98e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Norbert Matu≈°ka"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b5e07b7d91e94f9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-02T17:34:43.461300Z",
     "start_time": "2025-05-02T17:34:37.582598Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x00000182B0A2D7F0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matus\\PycharmProjects\\BP\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\matus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1513, in enumerate\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\matus\\PycharmProjects\\BP\\.venv\\Lib\\site-packages\\colorama\\ansitowin32.py\", line 47, in write\n",
      "  File \"C:\\Users\\matus\\PycharmProjects\\BP\\.venv\\Lib\\site-packages\\colorama\\ansitowin32.py\", line 177, in write\n",
      "  File \"C:\\Users\\matus\\PycharmProjects\\BP\\.venv\\Lib\\site-packages\\colorama\\ansitowin32.py\", line 205, in write_and_convert\n",
      "  File \"C:\\Users\\matus\\PycharmProjects\\BP\\.venv\\Lib\\site-packages\\colorama\\ansitowin32.py\", line 211, in write_plain_text\n",
      "  File \"C:\\Users\\matus\\PycharmProjects\\BP\\.venv\\Lib\\site-packages\\ipykernel\\iostream.py\", line 609, in flush\n",
      "  File \"C:\\Users\\matus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 634, in wait\n",
      "  File \"C:\\Users\\matus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 338, in wait\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import clickhouse_connect\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parser"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dad9565ae073a5e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Decodes and parses 802.11 wireless frame headers, extracting details like frame type, MAC addresses, and sequence information. It categorizes management, control, and data frames."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af70bb30283d0be2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "management_subtypes = {\n",
    "    0:  \"Association Request\",\n",
    "    1:  \"Association Response\",\n",
    "    2:  \"Reassociation Request\",\n",
    "    3:  \"Reassociation Response\",\n",
    "    4:  \"Probe Request\",\n",
    "    5:  \"Probe Response\",\n",
    "    6:  \"Timing Advertisement (11v)\",\n",
    "    7:  \"Reserved\",\n",
    "    8:  \"Beacon\",\n",
    "    9:  \"ATIM\",\n",
    "    10: \"Disassociation\",\n",
    "    11: \"Authentication\",\n",
    "    12: \"Deauthentication\",\n",
    "    13: \"Action\",\n",
    "    14: \"Action No Ack (11e)\",\n",
    "    15: \"Reserved\"\n",
    "}\n",
    "\n",
    "control_subtypes = {\n",
    "    0:   \"Reserved\",\n",
    "    1:   \"Reserved\",\n",
    "    2:   \"Trigger\",\n",
    "    3:   \"TACK\",\n",
    "    4:   \"Beamforming Report Poll\",\n",
    "    5:   \"VHT/HE NDP Announcement\",\n",
    "    6:   \"Reserved\",\n",
    "    7:   \"Control Wrapper\",\n",
    "    8:   \"Block Ack Request\",\n",
    "    9:   \"Block Ack\",\n",
    "    10:  \"PS-Poll\",\n",
    "    11:  \"RTS\",\n",
    "    12:  \"CTS\",\n",
    "    13:  \"ACK\",\n",
    "    14:  \"CF-End\",\n",
    "    15:  \"CF-End + CF-Ack\"\n",
    "}\n",
    "\n",
    "data_subtypes = {\n",
    "    0:   \"Data\",\n",
    "    1:   \"Data + CF-Ack\",\n",
    "    2:   \"Data + CF-Poll\",\n",
    "    3:   \"Data + CF-Ack + CF-Poll\",\n",
    "    4:   \"Null Function (No Data)\",\n",
    "    5:   \"CF-Ack (No Data)\",\n",
    "    6:   \"CF-Poll (No Data)\",\n",
    "    7:   \"CF-Ack + CF-Poll (No Data)\",\n",
    "    8:   \"QoS Data\",\n",
    "    9:   \"QoS Data + CF-Ack\",\n",
    "    10:  \"QoS Data + CF-Poll\",\n",
    "    11:  \"QoS Data + CF-Ack + CF-Poll\",\n",
    "    12:  \"QoS Null\",\n",
    "    13:  \"Reserved\",\n",
    "    14:  \"Reserved\",\n",
    "    15:  \"Reserved\"\n",
    "}\n",
    "\n",
    "frame_type_map = {\n",
    "    0: \"Management\",\n",
    "    1: \"Control\",\n",
    "    2: \"Data\",\n",
    "    3: \"Extension\"\n",
    "}\n",
    "\n",
    "TRANSLATED_HEADER_COLUMNS = [\n",
    "    \"frame_control_raw\",\n",
    "    \"protocol_version\",\n",
    "    \"frame_type\",\n",
    "    \"subtype\",\n",
    "\n",
    "    \"to_ds\",\n",
    "    \"from_ds\",\n",
    "    \"more_frag\",\n",
    "    \"retry\",\n",
    "    \"power_mgmt\",\n",
    "    \"more_data\",\n",
    "    \"protected_frame\",\n",
    "    \"order_flag\",\n",
    "\n",
    "    \"duration_id\",\n",
    "\n",
    "    \"destination_mac\",\n",
    "    \"source_mac\",\n",
    "    \"bssid_mac\",\n",
    "    \"address4_mac\",\n",
    "\n",
    "    \"sequence_control_raw\",\n",
    "    \"fragment_number\",\n",
    "    \"sequence_number\",\n",
    "\n",
    "    \"qos_control_raw\",\n",
    "    \"ht_control_raw\",\n",
    "\n",
    "    \"frame_body\"\n",
    "]\n",
    "\n",
    "\n",
    "def decode_header(header_b64):\n",
    "    try:\n",
    "        return base64.b64decode(header_b64)\n",
    "    except Exception as e:\n",
    "        print(f\"Error decoding header: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_probe_request(frame_body):\n",
    "\n",
    "    pos = 0\n",
    "    ies = {\n",
    "        \"ssid\": None,\n",
    "        \"supported_rates\": [],\n",
    "        \"extended_rates\": [],\n",
    "        \"vendor_specific\": []\n",
    "    }\n",
    "\n",
    "    while pos < len(frame_body):\n",
    "        if pos + 1 >= len(frame_body):\n",
    "            break\n",
    "\n",
    "        element_id = frame_body[pos]\n",
    "        element_len = frame_body[pos + 1]\n",
    "        pos += 2\n",
    "\n",
    "        if pos + element_len > len(frame_body):\n",
    "            break\n",
    "\n",
    "        element_data = frame_body[pos : pos + element_len]\n",
    "        pos += element_len\n",
    "\n",
    "        if element_id == 0:\n",
    "            ies[\"ssid\"] = element_data.decode(\"ascii\", errors=\"ignore\")\n",
    "        elif element_id == 1:\n",
    "            ies[\"supported_rates\"] = _decode_supported_rates(element_data)\n",
    "        elif element_id == 50:\n",
    "            ies[\"extended_rates\"] = _decode_supported_rates(element_data)\n",
    "        elif element_id == 221:\n",
    "            ies[\"vendor_specific\"].append(element_data)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return ies\n",
    "\n",
    "def _decode_supported_rates(rate_bytes):\n",
    "\n",
    "    rates = []\n",
    "    for r in rate_bytes:\n",
    "        rate_val = r & 0x7F  # strip off the 'basic rate' bit\n",
    "        # each unit = 500 kbps => multiply by 0.5 to get Mbps\n",
    "        rates.append(rate_val * 0.5)\n",
    "    return rates\n",
    "\n",
    "def translate_header(header_bytes):\n",
    "    if not header_bytes or len(header_bytes) < 24:\n",
    "        return [None] * len(TRANSLATED_HEADER_COLUMNS)\n",
    "\n",
    "    try:\n",
    "        # -----------------------------\n",
    "        # Frame Control\n",
    "        # -----------------------------\n",
    "        frame_control_raw = int.from_bytes(header_bytes[0:2], byteorder=\"little\")\n",
    "\n",
    "        protocol_version =  frame_control_raw & 0b11                # bits 0-1\n",
    "        frame_type       = (frame_control_raw >> 2) & 0b11          # bits 2-3\n",
    "        subtype          = (frame_control_raw >> 4) & 0b1111        # bits 4-7\n",
    "\n",
    "        # Flags\n",
    "        flags = (frame_control_raw >> 8) & 0xFF\n",
    "\n",
    "        to_ds           = bool(flags & 0b00000001)  # bit 8\n",
    "        from_ds         = bool(flags & 0b00000010)  # bit 9\n",
    "        more_frag       = bool(flags & 0b00000100)  # bit 10\n",
    "        retry           = bool(flags & 0b00001000)  # bit 11\n",
    "        power_mgmt      = bool(flags & 0b00010000)  # bit 12\n",
    "        more_data       = bool(flags & 0b00100000)  # bit 13\n",
    "        protected_frame = bool(flags & 0b01000000)  # bit 14\n",
    "        order_flag      = bool(flags & 0b10000000)  # bit 15\n",
    "\n",
    "        # -----------------------------\n",
    "        # Type/Subtype Description\n",
    "        # -----------------------------\n",
    "        type_description = frame_type_map.get(frame_type, \"Reserved\")\n",
    "\n",
    "        if frame_type == 0:\n",
    "            subtype_description = management_subtypes.get(subtype, \"Unknown\")\n",
    "        elif frame_type == 1:\n",
    "            subtype_description = control_subtypes.get(subtype, \"Unknown\")\n",
    "        elif frame_type == 2:\n",
    "            subtype_description = data_subtypes.get(subtype, \"Unknown\")\n",
    "        else:\n",
    "            # subtype mapping for 802.11n+ is more specialized\n",
    "            subtype_description = \"Extension/Reserved\"\n",
    "\n",
    "        # -----------------------------\n",
    "        # Duration/ID\n",
    "        # -----------------------------\n",
    "        duration_id = int.from_bytes(header_bytes[2:4], byteorder=\"little\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Addresses\n",
    "        # -----------------------------\n",
    "        address1 = _format_mac(header_bytes[4:10])\n",
    "        address2 = _format_mac(header_bytes[10:16])\n",
    "        address3 = _format_mac(header_bytes[16:22])\n",
    "\n",
    "        # Sequence Control\n",
    "        sequence_control_raw = int.from_bytes(header_bytes[22:24], byteorder=\"little\")\n",
    "        fragment_number = sequence_control_raw & 0x000F        # bits 0-3\n",
    "        sequence_number = (sequence_control_raw >> 4) & 0x0FFF  # bits 4-15\n",
    "\n",
    "        offset = 24\n",
    "        address4 = None\n",
    "\n",
    "        # if this is a data or QoS data frame with both To DS and From DS set => 4 addresses\n",
    "        if frame_type == 2 and to_ds and from_ds:\n",
    "            if len(header_bytes) >= offset + 6:\n",
    "                address4 = _format_mac(header_bytes[offset:offset+6])\n",
    "                offset += 6\n",
    "\n",
    "        # -----------------------------\n",
    "        # QoS Control\n",
    "        # -----------------------------\n",
    "        qos_control_raw = None\n",
    "        ht_control_raw = None\n",
    "\n",
    "        # if type is Data and the subtype >= 8 => likely QoS capable\n",
    "        if frame_type == 2 and subtype >= 8 and subtype <= 15:\n",
    "            if len(header_bytes) >= offset + 2:\n",
    "                qos_control_raw = int.from_bytes(header_bytes[offset:offset+2], byteorder=\"little\")\n",
    "                offset += 2\n",
    "\n",
    "            if order_flag:\n",
    "                if len(header_bytes) >= offset + 4:\n",
    "                    # some references say 4 bytes, others 2, 802.11n says 4. We parse 4 here\n",
    "                    ht_control_raw = header_bytes[offset:offset+4]\n",
    "                    offset += 4\n",
    "\n",
    "        frame_body = header_bytes[offset:]\n",
    "        \n",
    "        parsed_body = None\n",
    "        if type_description == \"Management\" and subtype_description == \"Probe Request\":\n",
    "            parsed_body = parse_probe_request(frame_body)\n",
    "\n",
    "        return {\n",
    "            # Protocol/Type/Subtype\n",
    "            \"protocol_version\": protocol_version,\n",
    "            \"frame_type\":       type_description,\n",
    "            \"subtype\":          subtype_description,\n",
    "\n",
    "            # Flags\n",
    "            \"to_ds\":            to_ds,\n",
    "            \"from_ds\":          from_ds,\n",
    "            \"more_frag\":        more_frag,\n",
    "            \"retry\":            retry,\n",
    "            \"power_mgmt\":       power_mgmt,\n",
    "            \"more_data\":        more_data,\n",
    "            \"protected_frame\":  protected_frame,\n",
    "            \"order_flag\":       order_flag,\n",
    "\n",
    "            # Others\n",
    "            \"duration_id\":      duration_id,\n",
    "\n",
    "            # Addresses\n",
    "            \"address1\": address1,\n",
    "            \"address2\": address2,\n",
    "            \"address3\": address3,\n",
    "            \"address4\": address4,\n",
    "\n",
    "            # Sequence\n",
    "            \"fragment_number\":  fragment_number,\n",
    "            \"sequence_number\":  sequence_number,\n",
    "\n",
    "            # QoS/HT/Body\n",
    "            \"qos_control_raw\":  qos_control_raw,\n",
    "            \"ht_control_raw\":   ht_control_raw.hex() if ht_control_raw else None,\n",
    "            \"frame_body\":       frame_body.hex()\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating header: {e}\")\n",
    "        return None\n",
    "\n",
    "def _format_mac(mac_bytes):\n",
    "    if len(mac_bytes) < 6:\n",
    "        return None\n",
    "    return \":\".join(f\"{b:02x}\" for b in mac_bytes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T17:34:43.464310Z",
     "start_time": "2025-05-02T17:34:43.463312Z"
    }
   },
   "id": "a82602a4fb6f498f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Extracts the OUI from MAC addresses and maps them to vendor names based on IEE oui DB."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69aea478fb7bd634"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_mac(mac):\n",
    "    return mac.replace(\":\", \"\").upper()[:6]\n",
    "oui_df = pd.read_csv(\"oui.csv\")\n",
    "oui_vendor_mapping = dict(zip(oui_df[\"Assignment\"], oui_df[\"Organization Name\"]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-02T17:34:43.465312Z"
    }
   },
   "id": "323c471d2e001478",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clickhouse connection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f4d8efcda37c70f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "password = os.environ.get(\"CLICKHOUSE_PASSWORD\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T17:34:43.467310Z",
     "start_time": "2025-05-02T17:34:43.467310Z"
    }
   },
   "id": "37a666387ac6cf82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client = clickhouse_connect.get_client(\n",
    "    host='localhost',\n",
    "    port=8123,\n",
    "    username='monad',\n",
    "    password=password\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-02T17:34:43.470308Z",
     "start_time": "2025-05-02T17:34:43.469308Z"
    }
   },
   "id": "676bf7ee0edcfab7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "source_table = \"monadcount.l2pk_v2\"\n",
    "parsed_table = \"monadcount.l2pk_v2_struct\"\n",
    "\n",
    "create_sql = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {parsed_table}\n",
    "(\n",
    "    id UUID,\n",
    "    protocol_version UInt8,\n",
    "    frame_type String,\n",
    "    subtype String,\n",
    "    to_ds UInt8,\n",
    "    from_ds UInt8,\n",
    "    more_frag UInt8,\n",
    "    retry UInt8,\n",
    "    power_mgmt UInt8,\n",
    "    more_data UInt8,\n",
    "    protected_frame UInt8,\n",
    "    order_flag UInt8,\n",
    "\n",
    "    duration_id UInt16,\n",
    "\n",
    "    address1 String,\n",
    "    address2 String,\n",
    "    address3 String,\n",
    "    address4 String,\n",
    "\n",
    "    fragment_number UInt16,\n",
    "    sequence_number UInt16,\n",
    "\n",
    "    qos_control_raw UInt16,\n",
    "    ht_control_raw String,\n",
    "    frame_body String,\n",
    "\n",
    "    vendor String\n",
    ")\n",
    "ENGINE = ReplacingMergeTree\n",
    "ORDER BY id\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-02T17:34:43.471311Z"
    }
   },
   "id": "81854b7a8838b89f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client.command(create_sql)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-02T17:34:43.472312Z"
    }
   },
   "id": "3b9e174588f5b3d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 50_000\n",
    "OFFSET = 0\n",
    "\n",
    "while True:\n",
    "    query = f\"\"\"\n",
    "        SELECT id, header\n",
    "        FROM {source_table}\n",
    "        LIMIT {CHUNK_SIZE} OFFSET {OFFSET}\n",
    "    \"\"\"\n",
    "    rows = client.query(query).named_results()\n",
    "    if not rows:\n",
    "        print(\"No more rows to process.\")\n",
    "        break\n",
    "\n",
    "    insert_data = []\n",
    "    for row in rows:\n",
    "        row_id = row[\"id\"]\n",
    "        header_b64 = row[\"header\"]\n",
    "\n",
    "        decoded = decode_header(header_b64)\n",
    "        parsed  = translate_header(decoded) if decoded else None\n",
    "        if not parsed:\n",
    "            continue\n",
    "\n",
    "        frame_type_str = parsed[\"frame_type\"]\n",
    "        from_ds        = parsed[\"from_ds\"]\n",
    "\n",
    "        # Figure out where the source MAC lives\n",
    "        if frame_type_str == \"Data\":\n",
    "            if from_ds:\n",
    "                source_mac = parsed[\"address3\"]\n",
    "            else:\n",
    "                source_mac = parsed[\"address2\"]\n",
    "        else:\n",
    "            source_mac = parsed[\"address2\"]\n",
    "\n",
    "        oui    = process_mac(source_mac or \"\")\n",
    "        vendor = oui_vendor_mapping.get(oui, \"Unknown\")\n",
    "\n",
    "        insert_data.append((\n",
    "            row_id,\n",
    "            parsed[\"protocol_version\"],\n",
    "            parsed[\"frame_type\"],\n",
    "            parsed[\"subtype\"],\n",
    "            parsed[\"to_ds\"],\n",
    "            parsed[\"from_ds\"],\n",
    "            parsed[\"more_frag\"],\n",
    "            parsed[\"retry\"],\n",
    "            parsed[\"power_mgmt\"],\n",
    "            parsed[\"more_data\"],\n",
    "            parsed[\"protected_frame\"],\n",
    "            parsed[\"order_flag\"],\n",
    "\n",
    "            parsed[\"duration_id\"],\n",
    "\n",
    "            parsed[\"address1\"],\n",
    "            parsed[\"address2\"],\n",
    "            parsed[\"address3\"],\n",
    "            parsed[\"address4\"] if parsed[\"address4\"] else \"\",\n",
    "\n",
    "            parsed[\"fragment_number\"],\n",
    "            parsed[\"sequence_number\"],\n",
    "\n",
    "            parsed[\"qos_control_raw\"],\n",
    "            parsed[\"ht_control_raw\"],\n",
    "            parsed[\"frame_body\"],\n",
    "\n",
    "            vendor\n",
    "        ))\n",
    "\n",
    "    if not insert_data:\n",
    "        print(f\"No valid rows in chunk (offset={OFFSET}).\")\n",
    "        OFFSET += CHUNK_SIZE\n",
    "        continue\n",
    "\n",
    "    client.insert(\n",
    "        parsed_table,\n",
    "        insert_data,\n",
    "        column_names=[\n",
    "            \"id\",\n",
    "            \"protocol_version\",\n",
    "            \"frame_type\",\n",
    "            \"subtype\",\n",
    "            \"to_ds\",\n",
    "            \"from_ds\",\n",
    "            \"more_frag\",\n",
    "            \"retry\",\n",
    "            \"power_mgmt\",\n",
    "            \"more_data\",\n",
    "            \"protected_frame\",\n",
    "            \"order_flag\",\n",
    "            \"duration_id\",\n",
    "            \"address1\",\n",
    "            \"address2\",\n",
    "            \"address3\",\n",
    "            \"address4\",\n",
    "            \"fragment_number\",\n",
    "            \"sequence_number\",\n",
    "            \"qos_control_raw\",\n",
    "            \"ht_control_raw\",\n",
    "            \"frame_body\",\n",
    "            \"vendor\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"Inserted {len(insert_data)} decoded rows (offset={OFFSET}).\")\n",
    "    OFFSET += CHUNK_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-02T17:34:43.474307Z"
    }
   },
   "id": "664aa1180f0a1ea3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Processes a large CSV file in chunks, decoding and translating headers, then combines the results into a final DataFrame for analysis.\n",
    "(old approach)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87d582afdbafe7a0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = []\n",
    "translated_headers = []\n",
    "for chunk in pd.read_csv(\"D:/monadcount_l2pk_v2_10000.csv\", chunksize=100000):\n",
    "    chunk[\"decoded_headers\"] = chunk[\"header\"].apply(decode_header)\n",
    "    chunk[\"translated_header\"] = chunk[\"decoded_headers\"].apply(translate_header)\n",
    "\n",
    "    data.append(chunk)\n",
    "\n",
    "data_df = pd.concat(data, ignore_index=True)\n",
    "data_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-02T17:34:43.476314Z"
    }
   },
   "id": "2ac2ef435010aa5c",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b1788b260f4e7d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Processes timestamp data to generate a heatmap of event occurrences by date and hour to check data continuity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "208b12d91c416c2c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def minute_to_hhmm(m):\n",
    "    hh = m // 60\n",
    "    mm = m % 60\n",
    "    return f\"{hh:02d}:{mm:02d}\"\n",
    "\n",
    "# GET ALL DEVICES (DISTINCT) FOR YEAR >= 2024\n",
    "devices_df = client.query_df(f\"\"\"\n",
    "    SELECT DISTINCT device\n",
    "    FROM {source_table}\n",
    "    WHERE toYear(happened_at) >= 2024\n",
    "\"\"\")\n",
    "devices = devices_df['device'].tolist()\n",
    "\n",
    "# BUILD A MASTER LIST OF ALL POSSIBLE DATES\n",
    "dates_df = client.query_df(f\"\"\"\n",
    "    SELECT DISTINCT toDate(happened_at) AS date\n",
    "    FROM {source_table}\n",
    "    WHERE toYear(happened_at) >= 2024\n",
    "    ORDER BY date\n",
    "\"\"\")\n",
    "all_dates = [d.date() for d in pd.to_datetime(dates_df['date'])]\n",
    "\n",
    "all_minutes = np.arange(1440)\n",
    "\n",
    "for device in devices:\n",
    "    print(f\"Processing device: {device}\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            toDate(happened_at) AS date,\n",
    "            toHour(happened_at)*60 + toMinute(happened_at) AS minute_of_day,\n",
    "            count(*) AS event_count\n",
    "        FROM {source_table}\n",
    "        WHERE toYear(happened_at) >= 2024\n",
    "          AND device = '{device}'\n",
    "        GROUP BY date, minute_of_day\n",
    "        ORDER BY date, minute_of_day\n",
    "    \"\"\"\n",
    "    agg_df = client.query_df(query)\n",
    "    if agg_df.empty:\n",
    "        print(f\"No data for device {device} in year >= 2024. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    agg_df['date'] = pd.to_datetime(agg_df['date']).dt.date\n",
    "\n",
    "    agg_df['has_data'] = (agg_df['event_count'] > 0).astype(int)\n",
    "\n",
    "    heatmap_pivot = agg_df.pivot(\n",
    "        index='date',\n",
    "        columns='minute_of_day',\n",
    "        values='has_data'\n",
    "    ).fillna(0)\n",
    "\n",
    "    heatmap_pivot = heatmap_pivot.reindex(columns=all_minutes, fill_value=0)\n",
    "    heatmap_pivot = heatmap_pivot.reindex(index=all_dates, fill_value=0)\n",
    "\n",
    "    # PLOT THE HEATMAP \n",
    "    plt.figure(figsize=(40, 10))\n",
    "    sns.heatmap(\n",
    "        heatmap_pivot,\n",
    "        cmap=\"Reds\",\n",
    "        cbar=False,\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"black\"\n",
    "    )\n",
    "    plt.xlabel(\"Time (HH:MM)\")\n",
    "    plt.ylabel(\"Date\")\n",
    "    plt.title(f\"Heatmap of Data Presence by Minute of the Day\\nDevice: {device}\")\n",
    "\n",
    "    ticks_step = 5\n",
    "    xtick_locs = range(0, 1440, ticks_step)\n",
    "    xtick_labels = [minute_to_hhmm(m) for m in xtick_locs]\n",
    "    plt.xticks(xtick_locs, xtick_labels, rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "    safe_device = str(device).replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "    plt.savefig(f\"activity_heatmaps/heatmap_{safe_device}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved heatmap for device: {device}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2369a3ae1a6c4aa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vendor_counts = data_df[\"vendor\"].value_counts()\n",
    "print(vendor_counts)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(vendor_counts.index, vendor_counts.values, log=True)\n",
    "plt.xlabel(\"Vendor\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"MAC Address Vendor Distribution (log scale)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53bb4f8cace301b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_norm = pd.json_normalize(data_df[\"translated_header\"])\n",
    "data_norm[\"frame_control.frame_type\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-02T17:34:43.481308Z"
    }
   },
   "id": "b88b615c6a9ab595",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "group_counts = data_norm.groupby(\n",
    "    [\"frame_control.frame_type\", \"frame_control.subtype\"]\n",
    ").size().reset_index(name=\"count\")\n",
    "\n",
    "group_counts.sort_values(\"count\", ascending=False, inplace=True)\n",
    "\n",
    "group_counts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "152e6ddfe262449d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Crowd counter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df664fd3b833e349"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function identifies static devices based on RSSI variance, grouping packets by src_MAC. Devices with consistently low RSSI variance across sniffers are classified as static.\n",
    "-- needs another condition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f32a9e45ab896348"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect_static_devices(datadf, rssi_threshold=1, chunksize=100000):\n",
    "    aggregator = {}\n",
    "\n",
    "    for start in range(0, len(datadf), chunksize):\n",
    "        chunk = datadf.iloc[start : start + chunksize]\n",
    "        # group by source_mac in the current chunk\n",
    "        for source_mac, group in chunk.groupby(\"source_mac\"):\n",
    "            # if first time seeing MAC\n",
    "            if source_mac not in aggregator:\n",
    "                aggregator[source_mac] = {\n",
    "                    \"sniffer_rssi\": defaultdict(list),\n",
    "                    \"sniffer_packet_count\": defaultdict(int),\n",
    "                    \"total_packet_count\": 0\n",
    "                }\n",
    "            \n",
    "            # now group by sniffer in this chunk\n",
    "            for sniffer_id, sniffer_group in group.groupby(\"device\"):\n",
    "                rssi_vals = sniffer_group[\"rssi\"].tolist()\n",
    "                aggregator[source_mac][\"sniffer_rssi\"][sniffer_id].extend(rssi_vals)\n",
    "                aggregator[source_mac][\"sniffer_packet_count\"][sniffer_id] += len(rssi_vals)\n",
    "            \n",
    "            aggregator[source_mac][\"total_packet_count\"] += len(group)\n",
    "\n",
    "    static_devices = []\n",
    "    for source_mac, data in aggregator.items():\n",
    "        sniffer_rssi = data[\"sniffer_rssi\"]\n",
    "        sniffer_packet_count = data[\"sniffer_packet_count\"]\n",
    "        total_packets = data[\"total_packet_count\"]\n",
    "\n",
    "        sniffer_variances = {}\n",
    "        all_below_threshold = True\n",
    "        max_variance = 0.0\n",
    "\n",
    "        for sniffer_id, rssi_values in sniffer_rssi.items():\n",
    "            variance = pd.Series(rssi_values).var()\n",
    "            sniffer_variances[sniffer_id] = variance\n",
    "            if pd.isna(variance) or variance >= rssi_threshold:\n",
    "                all_below_threshold = False\n",
    "                break\n",
    "            if variance > max_variance:\n",
    "                max_variance = variance\n",
    "\n",
    "        if all_below_threshold:            \n",
    "            detected_by_device = \",\".join(sniffer_rssi.keys())\n",
    "            static_devices.append({\n",
    "                \"source_mac\": source_mac,\n",
    "                \"rssi_variance\": max_variance,\n",
    "                \"detected_by_device\": detected_by_device,\n",
    "                \"packet_count\": total_packets,\n",
    "            })\n",
    "    return pd.DataFrame(static_devices)\n",
    "\n",
    "def extract_source_mac(row_dict):\n",
    "    if not row_dict or \"frame_control\" not in row_dict or \"addresses\" not in row_dict:\n",
    "        return None\n",
    "    \n",
    "    fc = row_dict[\"frame_control\"]\n",
    "    addrs = row_dict[\"addresses\"]\n",
    "    \n",
    "    to_ds = fc.get(\"to_ds\", False)\n",
    "    from_ds = fc.get(\"from_ds\", False)\n",
    "\n",
    "    # 802.11 logic\n",
    "    if not to_ds and not from_ds:\n",
    "        return addrs.get(\"address2\")\n",
    "    elif to_ds and not from_ds:\n",
    "        return addrs.get(\"address2\")\n",
    "    elif not to_ds and from_ds:\n",
    "        return addrs.get(\"address3\")\n",
    "    elif to_ds and from_ds:\n",
    "        # WDS bridging\n",
    "        return addrs.get(\"address4\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "data_df[\"source_mac\"] = data_df[\"translated_header\"].apply(extract_source_mac)\n",
    "\n",
    "static_devices = detect_static_devices(data_df)\n",
    "static_devices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "156cad9113539285"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
